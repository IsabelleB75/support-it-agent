# üìã FICHE PROJET FINAL MLOps - Data Engineering Bootcamp

---

## üéØ Informations g√©n√©rales

| √âl√©ment | D√©tail |
|---------|--------|
| **Dur√©e** | 180 minutes |
| **Module** | 7 - Final Projects |
| **Cours** | Pr√©parez votre projet final |
| **Objectif principal** | D√©velopper un pipeline MLOps enti√®rement fonctionnel qui automatise le cycle de vie complet d'un mod√®le de machine learning |

---

## üì¶ Livrables obligatoires

### 1. Rapport sur le dataset et le pr√©traitement
- Explication claire du dataset choisi
- Source des donn√©es (publique ou collect√©e)
- M√©thode de pr√©traitement appliqu√©e
- Gestion des valeurs manquantes
- Traitement des valeurs aberrantes
- √âquilibrage des donn√©es si n√©cessaire
- Feature engineering r√©alis√©
- Justification de chaque transformation

### 2. Notebook ou script du mod√®le entra√Æn√©
- Code d'entra√Ænement complet
- Choix de l'algorithme justifi√© (classification, r√©gression, clustering...)
- Framework utilis√© (TensorFlow, PyTorch, Scikit-learn)
- Hyperparameter tuning document√©
- √âvaluation avec m√©triques appropri√©es :
  - Accuracy
  - Precision
  - Recall
  - F1-score
  - Autres m√©triques selon le cas d'usage
- Mod√®le robuste et pr√™t pour la production

### 3. Pipeline MLOps complet
- **Sch√©ma d'architecture** du pipeline (diagramme visuel)
- **Code source** pour chaque composant :
  - D√©ploiement du mod√®le
  - Configuration CI/CD
  - Syst√®me de surveillance
  - Pipeline de r√©entra√Ænement
- **Vid√©o de pr√©sentation** ou captures d'√©cran montrant le processus en action

### 4. D√©p√¥t de code GitHub
- Code source complet et organis√©
- Instructions claires pour :
  - Installation des d√©pendances
  - Ex√©cution du pipeline
  - D√©ploiement complet
- README d√©taill√©

### 5. Documentation API
- Guide clair et concis
- Description des endpoints
- Format des entr√©es (inputs)
- Format des sorties (outputs)
- Exemples d'utilisation
- Instructions d'int√©gration pour tiers

### 6. Pr√©sentation (slides)
- Support visuel pour pr√©senter devant la classe ou le jury
- Structure recommand√©e : Introduction forte ‚Üí D√©veloppement ‚Üí Conclusion
- Utiliser le template Jedha : https://docs.google.com/presentation/d/1gFp4J8irQJs_5SrzTWxxQUUex8lHHTNXtEZ2P-a1VVM/edit?usp=sharing

---

## üèóÔ∏è Les 6 composants techniques obligatoires du pipeline

### a. D√©ploiement du mod√®le
- Conteneurisation avec **Docker**
- Orchestration avec **Kubernetes**
- Exposition via **API REST**
- D√©ploiement √©volutif (scalable)
- Capable de g√©rer donn√©es et requ√™tes en temps r√©el
- Options : AWS, Google Cloud, Azure ou on-premise

### b. CI/CD (Int√©gration Continue / D√©ploiement Continu)
- Outils possibles : **GitHub Actions**, GitLab CI, Jenkins
- Pipelines automatis√©s pour :
  - Tests automatiques
  - Validation du code
  - D√©ploiement automatique
- D√©clenchement √† chaque mise √† jour du mod√®le

### c. Surveillance et logging (Monitoring)
- Outils recommand√©s : **Evidently**, Aporia
- M√©triques √† suivre :
  - Latence des requ√™tes
  - Pr√©cision du mod√®le en production
  - D√©tection de drift (d√©rive des donn√©es)
- Configuration d'alertes :
  - Quand drift d√©tect√©
  - Quand pr√©cision descend sous un seuil d√©fini

### d. R√©entra√Ænement automatis√© (Continuous Training)
- Pipeline de retraining automatique
- D√©clencheurs :
  - D√©tection de drift par le monitoring
  - Nouvelles donn√©es disponibles
- Outils recommand√©s : **Apache Airflow**, Kubeflow
- Mise √† jour transparente du mod√®le en production

### e. Gestion des versions et rollback
- Outils recommand√©s : **MLflow**, DVC
- Versioning des donn√©es
- Versioning des mod√®les
- Capacit√© de rollback vers version pr√©c√©dente si probl√®me

### f. API document√©e
- Framework recommand√© : **FastAPI** (g√©n√®re /docs automatiquement)
- Documentation claire des :
  - Endpoints disponibles
  - Param√®tres d'entr√©e
  - Format de sortie
  - Codes d'erreur
- Faciliter l'int√©gration par des tiers

---

## ‚úÖ Crit√®res d'√©valuation (grille de notation)

### 1. Pr√©paration des donn√©es et performances du mod√®le
- Dataset pertinent et stimulant s√©lectionn√©
- Pr√©traitement correctement r√©alis√©
- Mod√®le performant entra√Æn√©
- M√©triques satisfaisantes

### 2. Exhaustivit√© du pipeline
- Pipeline couvre l'int√©gralit√© du cycle de vie :
  - D√©ploiement ‚úì
  - Surveillance ‚úì
  - R√©entra√Ænement ‚úì
- Tous les composants sont connect√©s

### 3. Automatisation
- Processus de d√©ploiement automatis√©
- Processus de retraining automatis√©
- Syst√®me robuste face aux changements de donn√©es
- Syst√®me robuste face aux baisses de performance

### 4. √âvolutivit√© et surveillance
- Pipeline capable de scaler (plus de donn√©es, plus d'utilisateurs)
- Monitoring proactif et efficace
- Alertes configur√©es et fonctionnelles

### 5. Documentation et accessibilit√©
- Pipeline clairement document√©
- Code lisible et comment√©
- Accessible aux futurs d√©veloppeurs
- Instructions reproductibles

---

## üîß Architecture existante (√©bauche Isabelle)

### Cas d'usage choisi
**Agent de support IT automatique**
- Classification automatique des tickets (sujet + urgence)
- G√©n√©ration de r√©ponses avec LLM (Mistral/OpenAI)

### Les 5 blocs du pipeline

#### Bloc 1 : Data Pipeline
```
PostgreSQL/Neon (raw tickets) 
    ‚Üí Airflow DAG (ingestion + transformation)
    ‚Üí dbt Core (transformation + tests)
    ‚Üí PostgreSQL/Neon (features/marts)
```

#### Bloc 2 : Training Pipeline
```
Airflow DAG training
    ‚Üí Ray (training distribu√© + tuning)
    ‚Üí MLflow Tracking (params + metrics + artefacts)
    ‚Üí Validation m√©triques (F1 + recall urgent)
    ‚Üí MLflow Registry (versioning + Production)
```

#### Bloc 3 : Deployment
```
Docker (build image)
    ‚Üí GitHub Actions (CI/CD)
    ‚Üí Kubernetes (deployment)
```

#### Bloc 4 : Serving (Production temps r√©el)
```
Utilisateur (ticket)
    ‚Üí FastAPI (K8s) - Pr√©diction sujet + urgence
    ‚Üí Knowledge Base (recherche contexte)
    ‚Üí API LLM externe (g√©n√©ration r√©ponse)
    ‚Üí R√©ponse √† l'utilisateur
    + Logs production (inputs + preds + latence + feedback)
```

#### Bloc 5 : Monitoring + Retraining
```
Logs production
    ‚Üí Airflow DAG monitoring
    ‚Üí Evidently (drift donn√©es + distribution pr√©dictions)
    ‚Üí Si drift d√©tect√© ‚Üí D√©clenche retraining (retour Bloc 2)
    ‚Üí Si pas de drift ‚Üí Continue surveillance
```

### Stack technique compl√®te
| Composant | Technologie |
|-----------|-------------|
| Base de donn√©es | PostgreSQL / Neon |
| Transformation donn√©es | dbt Core |
| Orchestration | Apache Airflow |
| Training distribu√© | Ray |
| Tracking ML | MLflow |
| Registry mod√®les | MLflow Model Registry |
| Conteneurisation | Docker |
| CI/CD | GitHub Actions |
| Orchestration containers | Kubernetes |
| API serving | FastAPI |
| Base de connaissances | Fichiers Markdown |
| LLM externe | Mistral / OpenAI API |
| Monitoring drift | Evidently AI |

---

## üìù Checklist des t√¢ches restantes

### Documents √† produire
- [ ] R√©diger le rapport sur le dataset et pr√©traitement
- [ ] Documenter le notebook d'entra√Ænement
- [ ] Cr√©er le sch√©ma d'architecture propre (export image)
- [ ] Structurer le repo GitHub avec README complet
- [ ] Enregistrer la vid√©o de d√©monstration
- [ ] V√©rifier la documentation API (/docs FastAPI)
- [ ] Cr√©er les slides de pr√©sentation

### Code √† impl√©menter/v√©rifier
- [ ] DAG Airflow : ingestion + dbt transformation
- [ ] DAG Airflow : training avec Ray
- [ ] DAG Airflow : monitoring Evidently
- [ ] Service FastAPI : chargement mod√®le depuis MLflow Registry
- [ ] Workflow GitHub Actions : build Docker + deploy K8s
- [ ] Manifests Kubernetes : Deployment + Service + ConfigMap
- [ ] Dockerfile optimis√©
- [ ] Tests unitaires et d'int√©gration

### Flux √† tester end-to-end
- [ ] Ingestion donn√©es ‚Üí Features disponibles
- [ ] Training ‚Üí Mod√®le enregistr√© dans Registry
- [ ] Push code ‚Üí CI/CD ‚Üí D√©ploiement automatique
- [ ] Requ√™te API ‚Üí Pr√©diction + R√©ponse LLM
- [ ] Logs ‚Üí Drift d√©tect√© ‚Üí Retraining d√©clench√©
- [ ] Rollback vers version pr√©c√©dente du mod√®le

---

## üìö Ressources pour trouver des donn√©es

### Open Data
- https://www.data.gov/
- https://www.enigma.com/
- https://snap.stanford.edu/data/index.html (donn√©es sociales)
- https://opendata.cityofnewyork.us/
- https://mattermark.com/
- https://www.crunchbase.com/
- https://www.kaggle.com/
- https://www.quandl.com/

### APIs publiques
- https://github.com/toddmotto/public-apis

### Inspiration projets IA
- https://experiments.withgoogle.com/collection/ai

### Recherche de datasets
- https://toolbox.google.com/datasetsearch

### Articles datasets Deep Learning
- https://www.analyticsvidhya.com/blog/2018/03/comprehensive-collection-deep-learning-datasets/

---

## üé§ Conseils pour la pr√©sentation orale

### Structure recommand√©e
1. **Introduction** - Commencer fort avec les meilleurs arguments
2. **D√©veloppement** - Approfondir l'argumentation
3. **Conclusion** - Reprendre les points cl√©s

### Storytelling
- Pr√©senter un personnage (utilisateur type)
- D√©crire le probl√®me/d√©fi qu'il rencontre
- Montrer les obstacles surmont√©s
- Raconter comment √ßa se termine (solution)

### Gestion du stress
- Power pose 30 secondes avant
- Bien manger avant (√©viter la malbouffe excessive)
- Exercice physique si possible
- Pr√©paration, pr√©paration, pr√©paration !

### Expression
- Parler plus fort que d'habitude
- Varier le rythme (ni trop vite, ni trop lent)
- √âviter la voix monotone
- Ne jamais tourner le dos au public
- Ne pas lire les slides, les m√©moriser

### R√®gles slides (Guy Kawasaki)
- Maximum 10 slides
- Maximum 20 minutes
- Police minimum 30pt
- 1 slide = 1 id√©e
- Contraste fort (fond clair/texte fonc√© ou inverse)

---

## üõ†Ô∏è Outils de conception projet

### Value Proposition Canvas
Framework pour trouver un cas d'usage business :
- Jobs to be done
- Pains (probl√®mes)
- Gains (b√©n√©fices attendus)
- Pain relievers
- Gain creators
- Products & Services

### AI Model Canvas (Jedha)
Framework sp√©cifique pour projets IA :
- Probl√®me √† r√©soudre
- Donn√©es n√©cessaires
- Mod√®le/algorithme
- Infrastructure
- M√©triques de succ√®s
- Risques et limitations

### Kanban (GitHub Projects)
- Visualiser les √©tapes du projet
- Colonnes : To Do ‚Üí In Progress ‚Üí Done
- Faciliter le suivi de progression

---

## ‚ö†Ô∏è Points d'attention importants

### MVP (Minimum Viable Product)
- Cr√©er un produit fonctionnel, pas parfait
- Pr√©dictions acceptables et utiles
- Utilisateurs finaux peuvent l'utiliser
- Ne pas y passer trop de temps

### Commencer petit, devenir grand
- R√©duire la port√©e initiale du projet
- Ne pas tout impl√©menter d'un coup (pas K8s + Spark + PyTorch d√®s le d√©part)
- Commencer en local, d√©ployer progressivement
- Penser microservices (services ind√©pendants)

### Cycle it√©ratif donn√©es/mod√®le
1. Collecter donn√©es (minimum n√©cessaire)
2. Construire mod√®le
3. Si r√©sultats insuffisants ‚Üí plus de donn√©es + meilleure EDA
4. R√©appliquer mod√®le + fine-tuning
5. R√©p√©ter jusqu'√† r√©sultats acceptables
6. Ne pas s'enliser : fixer un nombre max d'it√©rations

### Docker
- Tout conteneuriser le plus t√¥t possible
- Facilite la gestion en production
- Reproductibilit√© garantie

---

## üìÖ R√©capitulatif final

**Ce projet √©value ta capacit√© √† :**
1. Trouver et pr√©parer un dataset pertinent
2. Entra√Æner un mod√®le performant
3. Construire une infrastructure MLOps compl√®te
4. Automatiser le cycle de vie ML
5. Monitorer et maintenir un mod√®le en production
6. Documenter et pr√©senter ton travail

**Technologies cl√©s √† ma√Ætriser :**
- Docker + Kubernetes (d√©ploiement)
- Airflow (orchestration)
- MLflow (tracking + registry)
- Evidently (monitoring)
- GitHub Actions (CI/CD)
- FastAPI (serving)

**Ton avantage :** Tu as d√©j√† une architecture compl√®te et coh√©rente. Il te reste √† impl√©menter, documenter et pr√©senter.

---

*Fiche g√©n√©r√©e le 02/01/2026 - Projet Final MLOps Bootcamp Data Engineering*