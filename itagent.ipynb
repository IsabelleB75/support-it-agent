{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "369041d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: pyarrow in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (22.0.0)\n",
      "Requirement already satisfied: datasets[cli] in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (4.4.2)\n",
      "\u001b[33mWARNING: datasets 4.4.2 does not provide the extra 'cli'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: filelock in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets[cli]) (3.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets[cli]) (2.2.6)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets[cli]) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets[cli]) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets[cli]) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets[cli]) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets[cli]) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets[cli]) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets[cli]) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets[cli]) (0.36.0)\n",
      "Requirement already satisfied: packaging in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets[cli]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets[cli]) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets[cli]) (3.13.2)\n",
      "Requirement already satisfied: anyio in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from httpx<1.0.0->datasets[cli]) (4.12.0)\n",
      "Requirement already satisfied: certifi in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from httpx<1.0.0->datasets[cli]) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from httpx<1.0.0->datasets[cli]) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from httpx<1.0.0->datasets[cli]) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets[cli]) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets[cli]) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets[cli]) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[cli]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[cli]) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[cli]) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[cli]) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[cli]) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[cli]) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[cli]) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets[cli]) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from requests>=2.32.2->datasets[cli]) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from requests>=2.32.2->datasets[cli]) (2.6.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets[cli]) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets[cli] pandas pyarrow  # pyarrow pour Parquet\n",
    "# ou si tu pr√©f√®res conda/mamba :\n",
    "# conda install -c huggingface -c conda-forge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8390b515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b1aba3d8c743309de8280b599fa3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0dfeccd4c5e4661b02b9452bf429f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aa_dataset-tickets-multi-lang-5-2-50-ver(‚Ä¶):   0%|          | 0.00/26.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7f00be20794300a933ebb49350f620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(‚Ä¶)set-tickets-german_normalized_50_5_2.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685d630a0b674a8d8843f07327e16ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset-tickets-multi-lang-4-20k.csv:   0%|          | 0.00/18.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8264261d8c44ba4b7e31ff481c66f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/61765 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "facf124cc42b422eb2283c3515d4d55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sauvegard√© dans /home/isabelle/projects/bootcamp/jedha/projet_mlops_support\n",
      "['subject', 'body', 'answer', 'type', 'queue', 'priority', 'language', 'version', 'tag_1', 'tag_2', 'tag_3', 'tag_4', 'tag_5', 'tag_6', 'tag_7', 'tag_8']\n"
     ]
    }
   ],
   "source": [
    "# Cr√©e un script download_dataset.py\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "output_dir = \"/home/isabelle/projects/bootcamp/jedha/projet_mlops_support\"  # adapte le chemin\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Charge le dataset (t√©l√©charge auto si pas en cache)\n",
    "ds = load_dataset(\"Tobi-Bueck/customer-support-tickets\", split=\"train\")\n",
    "\n",
    "# Sauvegarde en Parquet (plus rapide/l√©ger pour ton pipeline)\n",
    "ds.to_parquet(os.path.join(output_dir, \"train.parquet\"))\n",
    "\n",
    "# Ou en CSV si tu pr√©f√®res\n",
    "# ds.to_csv(os.path.join(output_dir, \"train.csv\"))\n",
    "\n",
    "print(f\"Dataset sauvegard√© dans {output_dir}\")\n",
    "print(ds.column_names)  # Pour v√©rifier : ['queue', 'priority', 'language', 'subject', 'body', 'answer', ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a38136e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes et colonnes : (61765, 16)\n",
      "\n",
      "Noms des colonnes : ['subject', 'body', 'answer', 'type', 'queue', 'priority', 'language', 'version', 'tag_1', 'tag_2', 'tag_3', 'tag_4', 'tag_5', 'tag_6', 'tag_7', 'tag_8']\n",
      "\n",
      "Top 15 queues (sujets/d√©partements) :\n",
      "queue\n",
      "Technical Support                      14186\n",
      "Product Support                         8960\n",
      "Customer Service                        7420\n",
      "IT Support                              5725\n",
      "Billing and Payments                    4874\n",
      "Returns and Exchanges                   2438\n",
      "Service Outages and Maintenance         1912\n",
      "Sales and Pre-Sales                     1490\n",
      "Human Resources                          914\n",
      "General Inquiry                          668\n",
      "Pets & Animals/Pet Services              386\n",
      "News                                     383\n",
      "IT & Technology/Security Operations      365\n",
      "Autos & Vehicles/Sales                   364\n",
      "Health/Medical Services                  362\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Priorities (niveaux d'urgence) :\n",
      "priority\n",
      "medium      23378\n",
      "high        21925\n",
      "low         12765\n",
      "critical     1914\n",
      "very_low     1783\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Langues :\n",
      "language\n",
      "de    33504\n",
      "en    28261\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Exemple de ticket complet (ligne 0) :\n",
      "subject                       Wesentlicher Sicherheitsvorfall\n",
      "body        Sehr geehrtes Support-Team,\\n\\nich m√∂chte eine...\n",
      "answer      Vielen Dank f√ºr die Meldung des kritischen Sic...\n",
      "queue                                       Technical Support\n",
      "priority                                                 high\n",
      "\n",
      "Exemple de r√©ponse agent (premi√®re non vide) :\n",
      "Vielen Dank f√ºr die Meldung des kritischen Sicherheitsvorfalls und die Bereitstellung der √úbersicht √ºber die betroffenen Ger√§te sowie der ergriffenen ersten Ma√ünahmen. Wir erkennen die Dringlichkeit und Schwere der Lage an und setzen alles daran, den Fall priorit√§r zu bearbeiten. F√ºr eine umgehende Untersuchung ben√∂tigen wir zus√§tzliche Informationen: Bitte senden Sie uns spezifische Protokolle der betroffenen Projektoren, Bildschirme und Cloud-Speichersysteme, inklusive Zeitstempel verd√§chtiger Aktivit√§ten sowie ungew√∂hnlicher Fehlermeldungen. Falls m√∂glich, f√ºgen Sie auch eine Zusammenfassun\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Essaie d'abord le chemin relatif (si tu es dans le bon dossier)\n",
    "df = pd.read_parquet('train.parquet')\n",
    "\n",
    "# Si √ßa √©choue avec FileNotFound, utilise le chemin absolu (adapte selon ton pwd)\n",
    "# Exemples :\n",
    "# df = pd.read_parquet('/home/user/PROJECTS/bootcamp/jedha/projet_mlosps_support/train.parquet')\n",
    "# df = pd.read_parquet('./train.parquet')   # le ./ force relatif\n",
    "\n",
    "# Une fois charg√© :\n",
    "print(\"Nombre de lignes et colonnes :\", df.shape)\n",
    "print(\"\\nNoms des colonnes :\", df.columns.tolist())\n",
    "\n",
    "print(\"\\nTop 15 queues (sujets/d√©partements) :\")\n",
    "print(df['queue'].value_counts().head(15))\n",
    "\n",
    "print(\"\\nPriorities (niveaux d'urgence) :\")\n",
    "print(df['priority'].value_counts())\n",
    "\n",
    "print(\"\\nLangues :\")\n",
    "print(df['language'].value_counts())\n",
    "\n",
    "print(\"\\nExemple de ticket complet (ligne 0) :\")\n",
    "print(df[['subject', 'body', 'answer', 'queue', 'priority']].iloc[0].to_string())\n",
    "\n",
    "print(\"\\nExemple de r√©ponse agent (premi√®re non vide) :\")\n",
    "print(df[df['answer'].notna()]['answer'].iloc[0][:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27c177fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickets apr√®s filtre : 17893\n"
     ]
    }
   ],
   "source": [
    "# Filtre recommand√©\n",
    "df_tech_en = df[\n",
    "    (df['language'] == 'en') &\n",
    "    df['queue'].isin([\n",
    "        'Technical Support', 'IT Support', 'Product Support',\n",
    "        'Service Outages and Maintenance', 'IT & Technology/Security Operations'\n",
    "    ])\n",
    "].copy()\n",
    "\n",
    "print(\"Tickets apr√®s filtre :\", df_tech_en.shape[0])  # ~20-25k esp√©r√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b8d5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tickets apr√®s filtre EN + tech : 17893\n",
      "\n",
      "Distribution des queues apr√®s filtre :\n",
      " queue\n",
      "Technical Support                  8149\n",
      "Product Support                    5305\n",
      "IT Support                         3333\n",
      "Service Outages and Maintenance    1106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "R√©partition des priorities sur le sous-ensemble :\n",
      " priority\n",
      "high      8693\n",
      "medium    6767\n",
      "low       2433\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Urgence en 3 niveaux :\n",
      " urgency_level\n",
      "high      8693\n",
      "medium    6767\n",
      "low       2433\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assure-toi que df est d√©j√† charg√© (train.parquet)\n",
    "# Si pas le cas : df = pd.read_parquet('train.parquet')\n",
    "\n",
    "df_tech_en = df[\n",
    "    (df['language'] == 'en') &\n",
    "    df['queue'].isin([\n",
    "        'Technical Support', 'IT Support', 'Product Support',\n",
    "        'Service Outages and Maintenance', 'IT & Technology/Security Operations'\n",
    "    ])\n",
    "].copy()\n",
    "\n",
    "print(\"Nombre de tickets apr√®s filtre EN + tech :\", df_tech_en.shape[0])\n",
    "\n",
    "# V√©rification rapide des queues restantes (devrait √™tre limit√© aux 5 choisies)\n",
    "print(\"\\nDistribution des queues apr√®s filtre :\\n\", df_tech_en['queue'].value_counts())\n",
    "\n",
    "# R√©partition des urgences sur ce sous-ensemble\n",
    "print(\"\\nR√©partition des priorities sur le sous-ensemble :\\n\", df_tech_en['priority'].value_counts())\n",
    "\n",
    "# R√©partition des urgences mapp√©es en 3 niveaux (ajoute cette colonne)\n",
    "df_tech_en['urgency_level'] = df_tech_en['priority'].apply(\n",
    "    lambda p: 'high' if p in ['critical', 'high'] else 'medium' if p == 'medium' else 'low'\n",
    ")\n",
    "\n",
    "print(\"\\nUrgence en 3 niveaux :\\n\", df_tech_en['urgency_level'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b55a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegard√© : train_tech_en.parquet\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde le sous-ensemble filtr√© (pour ton pipeline Airflow/Postgres) :\n",
    "df_tech_en.to_parquet('train_tech_en.parquet', index=False)\n",
    "print(\"Sauvegard√© : train_tech_en.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07419f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urgency_level\n",
      "high      48.583245\n",
      "medium    37.819259\n",
      "low       13.597496\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Ajoute la colonne urgence (d√©j√† dans ton code) et v√©rifie distribution :\n",
    "print(df_tech_en['urgency_level'].value_counts(normalize=True) * 100)  # en %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac3fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.3 scikit-learn-1.7.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9a3c8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 12927 | Val: 2282 | Test: 2684\n"
     ]
    }
   ],
   "source": [
    "# Pr√©pare un petit split train/val/test (pour √©viter leakage RAG/SFT) :\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val, test = train_test_split(df_tech_en, test_size=0.15, random_state=42, stratify=df_tech_en['urgency_level'])\n",
    "train, val = train_test_split(train_val, test_size=0.15, random_state=42, stratify=train_val['urgency_level'])\n",
    "\n",
    "print(f\"Train: {len(train)} | Val: {len(val)} | Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "824d6c71",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "‚Üí Utilise train pour RAG index + SFT dataset\n",
    "‚Üí Val/test pour √©val drift (Evidently), accuracy classifier, qualit√© RAG/LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1e25537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '54466', 'title': 'Technical Support - Inquiry about Security Protocols for Safeguarding Medical Data', 'content': '\\nProbl√®me :\\nInquiry about Security Protocols for Safeguarding Medical Data\\nCould you please provide more information on the security measures implemented to protect sensitive medical data from unauthorized access, breaches, and security threats in our products and services? Specifically, I am interested in detailed information on the encryption methods used, access controls, and other security features that ensure the confidentiality, integrity, and availability of medical data. I would appreciate it if you could also provide a detailed explanation of these measures. I would prefer to follow up with a call at <tel_num> to discuss this further.\\n\\nR√©ponse agent typique :\\nWe will provide a detailed response regarding our medical data security protocols, including the encryption methods we use and our compliance with relevant regulations such as HIPAA. A follow-up call at <tel_num> would be preferred to discuss this further....\\n', 'metadata': {'queue': 'Technical Support', 'urgency': 'high', 'lang': 'en'}}\n"
     ]
    }
   ],
   "source": [
    "# G√©n√®re un exemple de document RAG (√† scaler plus tard) :\n",
    "\n",
    "def ticket_to_rag_doc(row):\n",
    "    return {\n",
    "        \"id\": str(row.name),\n",
    "        \"title\": f\"{row['queue']} - {row['subject'][:80]}\",\n",
    "        \"content\": f\"\"\"\n",
    "Probl√®me :\n",
    "{row['subject']}\n",
    "{row['body'][:800]}\n",
    "\n",
    "R√©ponse agent typique :\n",
    "{row['answer'][:600]}...\n",
    "\"\"\",\n",
    "        \"metadata\": {\n",
    "            \"queue\": row['queue'],\n",
    "            \"urgency\": row['urgency_level'],\n",
    "            \"lang\": row['language']\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Exemple pour la premi√®re ligne\n",
    "example_doc = ticket_to_rag_doc(train.iloc[0])\n",
    "print(example_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25863bb0",
   "metadata": {},
   "source": [
    "# Statut actuel du dataset filtr√© (`train_tech_en.parquet`)\n",
    "\n",
    "Parfait, tout est align√© maintenant ! Voici un r√©cap rapide de ton dataset filtr√© et pr√™t pour le pipeline MLOps :\n",
    "\n",
    "## Taille\n",
    "**17 893 tickets** (anglais + queues purement techniques)\n",
    "\n",
    "## Classes sujet (queue)\n",
    "4 classes naturelles et √©quilibr√©es :\n",
    "\n",
    "| Queue | Nombre | Pourcentage |\n",
    "|-------|--------|-------------|\n",
    "| Technical Support | ~8 149 | ~45.5% |\n",
    "| Product Support | ~5 305 | ~29.6% |\n",
    "| IT Support | ~3 333 | ~18.6% |\n",
    "| Service Outages and Maintenance | ~1 106 | ~6.2% |\n",
    "\n",
    "## Urgence (urgency_level)\n",
    "Bien r√©partie en 3 niveaux :\n",
    "\n",
    "| Niveau | Pourcentage | Nombre |\n",
    "|--------|-------------|--------|\n",
    "| high | 48.6% | ~8 693 |\n",
    "| medium | 37.8% | ~6 767 |\n",
    "| low | 13.6% | ~2 433 |\n",
    "\n",
    "## Split (stratifi√© sur urgency_level)\n",
    "\n",
    "| Split | Nombre | Pourcentage |\n",
    "|-------|--------|-------------|\n",
    "| Train | 12 927 | 72% |\n",
    "| Val | 2 282 | 13% |\n",
    "| Test | 2 684 | 15% |\n",
    "\n",
    "---\n",
    "\n",
    "## Exemple de doc RAG g√©n√©r√© (excellent)\n",
    "\n",
    "Ton exemple pour l'ID 54466 est typique et pr√™t √† l'emploi :\n",
    "\n",
    "- **title** : `Technical Support - Inquiry about Security Protocols for Safeguarding Medical Data`\n",
    "- **content** : combine parfaitement le probl√®me (subject + body) + r√©ponse agent (answer)\n",
    "- **metadata** : queue, urgency, lang ‚Üí super pour filtrage lors des retrieves\n",
    "\n",
    "---\n",
    "\n",
    "## C'est exactement ce qu'il faut pour :\n",
    "\n",
    "- **RAG** : vectoriser ces docs (sur train uniquement)\n",
    "- **Classification** : target = queue (4 classes) + urgency_level (3 classes)\n",
    "- **SFT** : prompt = subject + body ‚Üí output = answer\n",
    "\n",
    "---\n",
    "\n",
    "## Recommandation pour la suite (prochaines briques MLOps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58fc0d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (2.9.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ba71111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /home/isabelle/miniconda3/envs/rl/lib/python3.10/site-packages (2.9.11)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install psycopg2-binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d2c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f036ff",
   "metadata": {},
   "source": [
    "Note le port 5433 au lieu de 5432 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ce1bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table tickets_tech_en cr√©√©e !\n",
      "Tables dans support_tech : [('tickets_tech_en',)]\n"
     ]
    }
   ],
   "source": [
    "# Ingestion dans Postgres (DAG Airflow 1 ‚Äì ingestion & prep)\n",
    "#Cr√©e une table tickets_tech_en avec colonnes :\n",
    " # Connexion √† Postgres\n",
    "import psycopg2                                                                                                                                       \n",
    "                                                                                                                                                        \n",
    "  # Connexion √† la nouvelle DB bootcamp                                                                                                                 \n",
    "conn = psycopg2.connect(                                                                                                                              \n",
    "    host=\"localhost\",                                                                                                                                 \n",
    "    port=5433,  # Nouveau port !                                                                                                                      \n",
    "    database=\"support_tech\",                                                                                                                          \n",
    "    user=\"bootcamp_user\",                                                                                                                             \n",
    "    password=\"bootcamp_password\"                                                                                                                      \n",
    ")                                                                                                                                                     \n",
    "                                                                                                                                                    \n",
    "# Cr√©ation de la table                                                                                                                                \n",
    "cur = conn.cursor()                                                                                                                                   \n",
    "cur.execute(\"\"\"                                                                                                                                       \n",
    "CREATE TABLE IF NOT EXISTS tickets_tech_en (                                                                                                          \n",
    "    id SERIAL PRIMARY KEY,                                                                                                                            \n",
    "    subject TEXT,                                                                                                                                     \n",
    "    body TEXT,                                                                                                                                        \n",
    "    answer TEXT,                                                                                                                                      \n",
    "    queue VARCHAR(100),\n",
    "    priority VARCHAR(50),\n",
    "    urgency_level VARCHAR(20),\n",
    "    language VARCHAR(10),\n",
    "    type VARCHAR(50),\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"Table tickets_tech_en cr√©√©e !\")\n",
    "\n",
    "# V√©rification\n",
    "cur.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';\")\n",
    "print(\"Tables dans support_tech :\", cur.fetchall())\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09faa78c",
   "metadata": {},
   "source": [
    "## üöÄ Prochaine √âtape : Ingestion dans Postgres via Airflow\n",
    "\n",
    "**Situation actuelle :**\n",
    "* ‚úÖ Dataset filtr√© et sauvegard√© : `train_tech_en.parquet`\n",
    "* ‚úÖ Structure de table Postgres : Pr√™te.\n",
    "\n",
    "**Objectif :** Passer √† l'ingestion r√©elle via un DAG Airflow.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Installation des paquets sur le VPS üì¶\n",
    "\n",
    "C'est la premi√®re √©tape concr√®te. Ex√©cute cette commande dans ton terminal (assure-toi d'√™tre dans ton environnement virtuel `venv` ou `conda`) :\n",
    "\n",
    "```bash\n",
    "pip install apache-airflow sqlalchemy psycopg2-binary pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65b26093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes actuelles :\n",
      "  - id: integer\n",
      "  - subject: text\n",
      "  - body: text\n",
      "  - answer: text\n",
      "  - queue: character varying\n",
      "  - priority: character varying\n",
      "  - urgency_level: character varying\n",
      "  - language: character varying\n",
      "  - type: character varying\n",
      "  - created_at: timestamp without time zone\n"
     ]
    }
   ],
   "source": [
    "import psycopg2                                                                                                                                       \n",
    "                                                                                                                                                    \n",
    "conn = psycopg2.connect(                                                                                                                              \n",
    "    host=\"localhost\",                                                                                                                                 \n",
    "    port=5433,                                                                                                                                        \n",
    "    database=\"support_tech\",                                                                                                                          \n",
    "    user=\"bootcamp_user\",                                                                                                                             \n",
    "    password=\"bootcamp_password\"                                                                                                                      \n",
    ")                                                                                                                                                     \n",
    "                                                                                                                                                    \n",
    "cur = conn.cursor()                                                                                                                                   \n",
    "cur.execute(\"\"\"                                                                                                                                       \n",
    "    SELECT column_name, data_type                                                                                                                     \n",
    "    FROM information_schema.columns                                                                                                                   \n",
    "    WHERE table_name = 'tickets_tech_en'                                                                                                              \n",
    "    ORDER BY ordinal_position;                                                                                                                        \n",
    "\"\"\")                                                                                                                                                  \n",
    "print(\"Colonnes actuelles :\")                                                                                                                         \n",
    "for row in cur.fetchall():                                                                                                                            \n",
    "    print(f\"  - {row[0]}: {row[1]}\")                                                                                                                  \n",
    "                                                                                                                                                    \n",
    "cur.close()                                                                                                                                           \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38dfe379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes tag_1, tag_2, tag_3 ajout√©es !\n"
     ]
    }
   ],
   "source": [
    "import psycopg2                                                                                                                                       \n",
    "                                                                                                                                                    \n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=5433,\n",
    "    database=\"support_tech\",\n",
    "    user=\"bootcamp_user\",\n",
    "    password=\"bootcamp_password\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "    ALTER TABLE tickets_tech_en \n",
    "    ADD COLUMN IF NOT EXISTS tag_1 VARCHAR(100),\n",
    "    ADD COLUMN IF NOT EXISTS tag_2 VARCHAR(100),\n",
    "    ADD COLUMN IF NOT EXISTS tag_3 VARCHAR(100);\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"Colonnes tag_1, tag_2, tag_3 ajout√©es !\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e3a0449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure de tickets_tech_en :\n",
      "  id: integer\n",
      "  subject: text\n",
      "  body: text\n",
      "  answer: text\n",
      "  queue: character varying\n",
      "  priority: character varying\n",
      "  urgency_level: character varying\n",
      "  language: character varying\n",
      "  type: character varying\n",
      "  created_at: timestamp without time zone\n",
      "  tag_1: character varying\n",
      "  tag_2: character varying\n",
      "  tag_3: character varying\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=5433,\n",
    "    database=\"support_tech\",\n",
    "    user=\"bootcamp_user\",\n",
    "    password=\"bootcamp_password\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_name = 'tickets_tech_en'\n",
    "    ORDER BY ordinal_position;\n",
    "\"\"\")\n",
    "\n",
    "print(\"Structure de tickets_tech_en :\")\n",
    "for col in cur.fetchall():\n",
    "    print(f\"  {col[0]}: {col[1]}\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8cbe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total : 17893 tickets\n",
      "\n",
      "Aper√ßu :\n",
      "  - Account Disruption... | Technical Support | high\n",
      "  - Feature Query... | Technical Support | high\n",
      "  - System Interruptions... | Service Outages and Maintenance | high\n",
      "  - Connectivity Problems with Printer on MacBook Pro... | Technical Support | medium\n",
      "  - VPN Access Issue... | Product Support | medium\n"
     ]
    }
   ],
   "source": [
    "# apres le trigger du dag d'ingestion on va verifier si tout est tok \n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=5433,\n",
    "    database=\"support_tech\",\n",
    "    user=\"bootcamp_user\",\n",
    "    password=\"bootcamp_password\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Compte\n",
    "cur.execute(\"SELECT COUNT(*) FROM tickets_tech_en;\")\n",
    "print(f\"Total : {cur.fetchone()[0]} tickets\")\n",
    "\n",
    "# Aper√ßu 5 lignes\n",
    "cur.execute(\"SELECT subject, queue, urgency_level FROM tickets_tech_en LIMIT 5;\")\n",
    "print(\"\\nAper√ßu :\")\n",
    "for row in cur.fetchall():\n",
    "    print(f\"  - {row[0][:50]}... | {row[1]} | {row[2]}\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fddcce8",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ‚úÖ Validation Ingestion & Plan DAG 2\n",
    "\n",
    "### 1. Statut de l'ingestion : Succ√®s ! üéâ\n",
    "\n",
    "* **Total :** **17 893 tickets** dans la table `tickets_tech_en`.\n",
    "* **Int√©grit√© :** Cela correspond exactement √† la taille du fichier filtr√© `train_tech_en.parquet` (aucune perte de lignes).\n",
    "* **Qualit√© :** Les 5 exemples affich√©s montrent que les colonnes principales (`subject`, `queue`, `urgency_level`) sont bien remplies et coh√©rentes.\n",
    "\n",
    "üëâ **Conclusion :** Tout est OK c√¥t√© ingestion, on passe √† la suite !\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Objectif du DAG 2 : Pr√©paration & Feature Engineering üõ†Ô∏è\n",
    "\n",
    "Ce DAG va transformer les donn√©es brutes en donn√©es pr√™tes pour le Machine Learning.\n",
    "\n",
    "**Les √©tapes cl√©s :**\n",
    "\n",
    "1.  **Lecture :** Charger les donn√©es depuis Postgres (`tickets_tech_en`).\n",
    "2.  **Nettoyage (Cleaning) :**\n",
    "    * Nettoyer `body` et `answer` (suppression balises HTML, normalisation espaces).\n",
    "    * (Optionnel) Anonymisation basique (suppression t√©l√©phones/emails).\n",
    "3.  **Feature Engineering :**\n",
    "    * üìè **Longueurs :** Calculer `body_length` et `answer_length`.\n",
    "    * üîë **Keywords :** D√©tecter la pr√©sence de mots-cl√©s pour raffiner les sujets (ex: *vpn, printer, network, security, login*).\n",
    "    * üìä **Ratios :** Calculer le ratio r√©ponse/probl√®me (pour identifier les tickets bien r√©solus).\n",
    "4.  **Sauvegarde :** Stocker le r√©sultat dans une nouvelle table : `tickets_tech_en_enriched`.\n",
    "5.  **Monitoring (Optionnel) :** G√©n√©rer un rapport **Evidently** (Qualit√© de donn√©es + Distribution des features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd7e3304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total : 17893 tickets enrichis\n",
      "(544, 495, 0.908256880733945, 0, 1)\n",
      "(646, 152, 0.23493044822256567, 0, 0)\n",
      "(568, 541, 0.9507908611599297, 1, 0)\n",
      "(513, 499, 0.9708171206225681, 0, 0)\n",
      "(142, 39, 0.2727272727272727, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "# le dag 2 vient de se terminer avec succ√®s ! \n",
    "\n",
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\", port=5433,\n",
    "    database=\"support_tech\",\n",
    "    user=\"bootcamp_user\", password=\"bootcamp_password\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT COUNT(*) FROM tickets_tech_en_enriched;\")\n",
    "print(f\"Total : {cur.fetchone()[0]} tickets enrichis\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT body_length, answer_length, response_ratio, has_network, has_security \n",
    "    FROM tickets_tech_en_enriched LIMIT 5;\n",
    "\"\"\")\n",
    "for row in cur.fetchall():\n",
    "    print(row)\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027f82b1",
   "metadata": {},
   "source": [
    "Explication du rapport Drift                                                                \n",
    "                                                                                              \n",
    "  Qu'est-ce que le Data Drift ?                                                               \n",
    "                                                                                              \n",
    "  Le drift c'est quand la distribution des donn√©es change entre deux p√©riodes. On compare ici \n",
    "la premi√®re moiti√© des tickets (9000) vs la seconde moiti√© (8893).                            \n",
    "\n",
    "  R√©sultat global\n",
    "\n",
    "  Dataset Drift is NOT detected (seuil 0.5)\n",
    "  ‚Üí Globalement, tes donn√©es sont stables ! Pas d'alerte majeure.\n",
    "\n",
    "  D√©tail par colonne\n",
    "\n",
    "  | Colonne        | Drift ? | Distance | Signification                                     |\n",
    "  |----------------|---------|----------|---------------------------------------------------|\n",
    "  | body_length    | ‚ö†Ô∏è  Oui  | 0.20     | Les tickets r√©cents sont un peu plus longs/courts |  | answer_length  | ‚ö†Ô∏è  Oui  | 0.14     | Les r√©ponses varient l√©g√®rement                   |  | response_ratio | ‚ö†Ô∏è  Oui  | 0.11     | L√©ger changement dans le ratio r√©ponse/probl√®me   |  | has_network    | ‚úÖ Non  | 0.03     | Stable                                            |\n",
    "  | has_hardware   | ‚úÖ Non  | 0.02     | Stable                                            |\n",
    "  | has_printer    | ‚úÖ Non  | 0.02     | Stable                                            |\n",
    "  | has_software   | ‚úÖ Non  | 0.01     | Stable                                            |\n",
    "  | has_security   | ‚úÖ Non  | 0.01     | Stable                                            |\n",
    "\n",
    "  Ce que √ßa veut dire pour ton projet\n",
    "\n",
    "  1. Les cat√©gories de tickets sont stables ‚Üí Bon pour la classification !\n",
    "  2. La longueur des textes varie un peu ‚Üí Normal, certains tickets sont plus d√©taill√©s\n",
    "  3. Pas besoin de r√©entra√Æner le mod√®le si ces m√©triques restent dans ces valeurs\n",
    "\n",
    "  ---\n",
    "  En production, tu surveillerais ce rapport r√©guli√®rement. Si le drift d√©passe 0.5 ‚Üí alerte pour r√©entra√Æner le mod√®le.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a97f5c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes de tickets_tech_en_enriched :\n",
      "  - subject\n",
      "  - body\n",
      "  - answer\n",
      "  - type\n",
      "  - queue\n",
      "  - priority\n",
      "  - language\n",
      "  - version\n",
      "  - tag_1\n",
      "  - tag_2\n",
      "  - tag_3\n",
      "  - tag_4\n",
      "  - tag_5\n",
      "  - tag_6\n",
      "  - tag_7\n",
      "  - tag_8\n",
      "  - urgency_level\n",
      "  - body_clean\n",
      "  - answer_clean\n",
      "  - body_length\n",
      "  - answer_length\n",
      "  - response_ratio\n",
      "  - has_network\n",
      "  - has_printer\n",
      "  - has_security\n",
      "  - has_hardware\n",
      "  - has_software\n",
      "\n",
      "Exemple de donn√©es enrichies :\n",
      "('Dear Customer Support Team,\\\\n\\\\nI am writing to report a significant problem with the centralized account management portal, which currently appears to be offline. This outage is blocking access to account settings, leading to substantial inconvenience. I have attempted to log in multiple times using different browsers and devices, but the issue persists.\\\\n\\\\nCould you please provide an update on the outage status and an estimated time for resolution? Also, are there any alternative ways to access and manage my account during this downtime?', 'Thank you for reaching out, . We are aware of the outage affecting the centralized account management system, and our technical team is actively working to resolve the issue. In the meantime, we suggest using alternative methods to manage your account, with a focus on restoring service as quickly as possible. We will provide an update as soon as the service is back online. We apologize for the inconvenience and appreciate your patience. If you have any further questions, please let us know.', 544, 495, 0.908256880733945, 0, 0, 1, 0, 1)\n",
      "('Dear Customer Support,\\\\n\\\\nI hope this message reaches you in good health. I am eager to learn more about the features of one of your products. Would you be able to share comprehensive details about its functionalities, specifications, and any distinctive characteristics it may possess? Additionally, if there are user manuals, tutorials, or demonstration videos available, I would be grateful if you could provide those resources. Gaining a thorough understanding of the features will assist me in making an informed decision regarding the product.\\\\n\\\\nThank you very much for your assistance. I look forward to your prompt reply.\\\\n\\\\nBest regards', 'Thank you for your inquiry. Please specify which product you are interested in, so I can provide detailed information, features, and relevant resources.', 646, 152, 0.23493044822256567, 0, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\", port=5433,\n",
    "    database=\"support_tech\",\n",
    "    user=\"bootcamp_user\", password=\"bootcamp_password\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Liste toutes les colonnes\n",
    "cur.execute(\"\"\"\n",
    "    SELECT column_name FROM information_schema.columns \n",
    "    WHERE table_name = 'tickets_tech_en_enriched'\n",
    "    ORDER BY ordinal_position;\n",
    "\"\"\")\n",
    "print(\"Colonnes de tickets_tech_en_enriched :\")\n",
    "for col in cur.fetchall():\n",
    "    print(f\"  - {col[0]}\")\n",
    "\n",
    "# V√©rifie les nouvelles colonnes\n",
    "cur.execute(\"\"\"\n",
    "    SELECT body_clean, answer_clean, body_length, answer_length, response_ratio,\n",
    "            has_network, has_printer, has_security, has_hardware, has_software\n",
    "    FROM tickets_tech_en_enriched LIMIT 2;\n",
    "\"\"\")\n",
    "print(\"\\nExemple de donn√©es enrichies :\")\n",
    "for row in cur.fetchall():\n",
    "    print(row)\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a20f4",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ‚úÖ V√©rification et Analyse : Ingestion & Feature Engineering\n",
    "\n",
    "**√âtat g√©n√©ral :** Tout est nickel ! üéâ\n",
    "* **Ingestion :** Succ√®s. La table `tickets_tech_en` contient bien **17 893 lignes**.\n",
    "* **Feature Engineering :** Le DAG a fonctionn√©, la table `tickets_tech_en_enriched` est cr√©√©e avec les colonnes nettoy√©es et les features calcul√©es.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Analyse des Colonnes Enrichies üßê\n",
    "Les nouvelles features sont bien pr√©sentes en base :\n",
    "* **Texte nettoy√© :** `body_clean`, `answer_clean`\n",
    "* **M√©triques de longueur :** `body_length`, `answer_length`, `response_ratio`\n",
    "* **Keywords (Flags) :** `has_network`, `has_printer`, `has_security`, `has_hardware`, `has_software`\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Exemples de Donn√©es & Interpr√©tation üìä\n",
    "\n",
    "Voici une analyse de quelques lignes extraites (format : *Body Len / Answer Len / Ratio / Network / Printer*) :\n",
    "\n",
    "| Ticket | Body Len | Ans Len | Ratio | Flags actifs | Interpr√©tation |\n",
    "| :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "| **#1** | 544 | 495 | **0.91** | - | **R√©ponse d√©taill√©e :** La r√©ponse est presque aussi longue que le probl√®me. |\n",
    "| **#2** | 646 | 152 | **0.23** | - | **R√©ponse concise :** Probl√®me long mais solution courte/rapide. |\n",
    "| **#3** | 568 | 541 | **0.95** | `has_network=1` | **Ticket R√©seau :** Probl√®me de connectivit√© avec une r√©solution compl√®te. |\n",
    "| **#4** | 513 | 499 | **0.97** | - | Ratio √©quilibr√©. |\n",
    "| **#5** | 142 | 39 | **0.27** | `has_printer=1` | **Ticket Imprimante :** Question courte, r√©ponse exp√©ditive (ex: \"Reboot\"). |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Rapport de Drift (Evidently) üìâ\n",
    "*Comparaison : Premi√®re moiti√© vs Seconde moiti√© du dataset.*\n",
    "\n",
    "* **üü¢ Dataset Drift : NOT DETECTED**\n",
    "    * *Conclusion :* Les donn√©es sont globalement stables. C'est excellent pour entra√Æner un mod√®le fiable.\n",
    "* **Observations :**\n",
    "    * **L√©ger drift sur les longueurs** (*body_length*, etc.) : Normal dans le support, les tickets tendent √† devenir plus d√©taill√©s ou changer de format avec le temps.\n",
    "    * **Stabilit√© des Keywords** (*has_**): Pas de nouveaux types de probl√®mes majeurs d√©tect√©s.\n",
    "\n",
    "üëâ **Action :** Pas besoin de r√©entra√Æner pour l'instant. En production, ce rapport devra √™tre g√©n√©r√© mensuellement.\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Next Steps\n",
    "Priorit√© maintenant : **Explorer la table enrichie via SQL** pour valider la distribution des nouvelles classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd2abf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Moyennes des features ===\n",
      "Body length moyen     : 371 caract√®res\n",
      "Answer length moyen   : 368 caract√®res\n",
      "Response ratio moyen  : 1.46\n",
      "\n",
      "=== % de tickets par th√®me ===\n",
      "Network  : 10.9%\n",
      "Security : 23.3%\n",
      "Software : 36.4%\n",
      "Hardware : 4.9%\n",
      "Printer  : 0.8%\n",
      "\n",
      "=== Top 5 tickets Security ===\n",
      "\n",
      "[high] Technical Support\n",
      "  Subject: Account Disruption\n",
      "  Body: Dear Customer Support Team,\\n\\nI am writing to report a significant problem with the centralized acc...\n",
      "\n",
      "[high] Technical Support\n",
      "  Subject: Customer Support for Data Breach\n",
      "  Body: A healthcare organization identified unauthorized access attempts. Password resets have been carried...\n",
      "\n",
      "[medium] IT Support\n",
      "  Subject: Immediate Help Needed: Technical Problem with Cloud SaaS Service\n",
      "  Body: Dear Customer Support Team,\\n\\nI am submitting a report regarding a technical problem encountered wi...\n",
      "\n",
      "[medium] Service Outages and Maintenance\n",
      "  Subject: Query About Future Service Disruptions and Maintenance Timelines\n",
      "  Body: Dear Customer Support Team,\\n\\nI hope this message finds you well. I am reaching out to request deta...\n",
      "\n",
      "[high] Technical Support\n",
      "  Subject: Assistance Required for Data Security Incident\n",
      "  Body: A healthcare organization has suffered data breaches due to outdated security measures. Efforts to u...\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(                                                                    \n",
    "    host=\"localhost\", port=5433,                                                            \n",
    "    database=\"support_tech\",                                                                \n",
    "    user=\"bootcamp_user\", password=\"bootcamp_password\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Moyennes des features\n",
    "cur.execute(\"\"\"\n",
    "    SELECT \n",
    "        AVG(body_length) AS avg_body_len,\n",
    "        AVG(answer_length) AS avg_answer_len, \n",
    "        AVG(response_ratio) AS avg_ratio,\n",
    "        AVG(has_network) AS pct_network,\n",
    "        AVG(has_security) AS pct_security,\n",
    "        AVG(has_software) AS pct_software,\n",
    "        AVG(has_hardware) AS pct_hardware,\n",
    "        AVG(has_printer) AS pct_printer\n",
    "    FROM tickets_tech_en_enriched;\n",
    "\"\"\")\n",
    "row = cur.fetchone()\n",
    "print(\"=== Moyennes des features ===\")\n",
    "print(f\"Body length moyen     : {row[0]:.0f} caract√®res\")\n",
    "print(f\"Answer length moyen   : {row[1]:.0f} caract√®res\")\n",
    "print(f\"Response ratio moyen  : {row[2]:.2f}\")\n",
    "print(f\"\\n=== % de tickets par th√®me ===\")\n",
    "print(f\"Network  : {row[3]*100:.1f}%\")\n",
    "print(f\"Security : {row[4]*100:.1f}%\")\n",
    "print(f\"Software : {row[5]*100:.1f}%\")\n",
    "print(f\"Hardware : {row[6]*100:.1f}%\")\n",
    "print(f\"Printer  : {row[7]*100:.1f}%\")\n",
    "\n",
    "# Top 5 tickets s√©curit√©\n",
    "print(\"\\n=== Top 5 tickets Security ===\")\n",
    "cur.execute(\"\"\"\n",
    "    SELECT subject, queue, urgency_level, LEFT(body_clean, 100) as body_preview\n",
    "    FROM tickets_tech_en_enriched\n",
    "    WHERE has_security = 1\n",
    "    LIMIT 5;\n",
    "\"\"\")\n",
    "for row in cur.fetchall():\n",
    "    print(f\"\\n[{row[2]}] {row[1]}\")\n",
    "    print(f\"  Subject: {row[0]}\")\n",
    "    print(f\"  Body: {row[3]}...\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b13c31",
   "metadata": {},
   "source": [
    "### üöÄ Synth√®se et Suggestions : Exploitation des Keywords\n",
    "\n",
    "Parfait, on avance bien ! Voici une synth√®se rapide de ce que tu as partag√©, et des suggestions pour exploiter ces infos dans ton projet bootcamp.\n",
    "\n",
    "#### 1. Analyse des keywords / th√®mes √©mergents üìä\n",
    "Apr√®s avoir calcul√© les features `has_*` dans le DAG de prep, tu as ces proportions approximatives sur les **17 893 tickets** (bas√© sur *AVG(has_*) * 100*) :\n",
    "\n",
    "* **Software : 36.4%**\n",
    "    * ‚Üí Th√®me dominant : bugs, mises √† jour, installations, crashes, versions de produits.\n",
    "    * ‚Üí Tr√®s coh√©rent avec *Product Support* (29.6%) et *Technical Support*.\n",
    "* **Hardware : 4.9%**\n",
    "    * ‚Üí Moins fr√©quent : laptops, √©crans, disques, CPU, MacBook.\n",
    "    * ‚Üí Souvent li√© √† *IT Support* (18.6%).\n",
    "* **Printer : 0.8%**\n",
    "    * ‚Üí Rare : imprimantes, scan, print jobs.\n",
    "    * ‚Üí Niche mais concret pour le support technique.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Proposition de raffinement des classes üõ†Ô∏è\n",
    "C'est une bonne base pour raffiner tes classes sujet au-del√† des 4 queues principales. Voici une proposition de **6 √† 8 classes** :\n",
    "\n",
    "| Classe √©largie (Proposition) | Base (Queue) + Keywords | % Approx. | Commentaire |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Software / Product** | Product Support + `has_software` | ~36‚Äì40% | Dominant, bugs & apps |\n",
    "| **General Technical Support** | Technical Support (sans keywords) | ~30‚Äì35% | \"Catch-all\" technique |\n",
    "| **IT Infrastructure / Network** | IT Support + `has_network` | ~15‚Äì20% | VPN, connexion, infra |\n",
    "| **Hardware / Device** | IT Support + `has_hardware` | ~5‚Äì7% | Machines physiques |\n",
    "| **Service Outages / Maintenance** | Service Outages... | ~6% | Pannes planifi√©es |\n",
    "| **Security / Access** | `has_security` | ~2‚Äì5% | Incidents sensibles (faible % mais critique) |\n",
    "| **Printer / Peripherals** | `has_printer` | ~1% | Tr√®s sp√©cifique |\n",
    "\n",
    "üëâ **Action :** Tu peux cr√©er une colonne `sub_category` ou `refined_queue` dans la table enrichie pour impl√©menter cette logique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05fe99d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### üîê Analyse des Top 5 tickets avec `has_security = 1`\n",
    "\n",
    "Ces 5 exemples montrent bien la pertinence du th√®me s√©curit√© dans ton dataset :\n",
    "\n",
    "* **[High] Technical Support ‚Äì Account Disruption**\n",
    "    * *Analyse :* Probl√®me de compte centralis√© compromis ‚Üí urgence haute ‚Üí **typique incident de s√©curit√©** (acc√®s non autoris√©).\n",
    "* **[High] Technical Support ‚Äì Customer Support for Data Breach**\n",
    "    * *Analyse :* Acc√®s non autoris√© sur organisation sant√© ‚Üí password resets ‚Üí urgence haute ‚Üí **Data Breach clair**.\n",
    "* **[Medium] IT Support ‚Äì Immediate Help Needed: Technical Problem with Cloud SaaS Service**\n",
    "    * *Analyse :* Probl√®me technique SaaS ‚Üí pas explicitement breach, mais peut inclure une vuln√©rabilit√©.\n",
    "* **[Medium] Service Outages and Maintenance ‚Äì Query About Future Service Disruptions**\n",
    "    * *Analyse :* Question sur interruptions futures ‚Üí moins \"s√©curit√©\", plus maintenance ‚Üí **Potentiel faux positif** du mot-cl√©.\n",
    "* **[High] Technical Support ‚Äì Assistance Required for Data Security Incident**\n",
    "    * *Analyse :* Breach d√ª √† mesures de s√©curit√© obsol√®tes ‚Üí urgence haute ‚Üí **Cas critique sant√©**.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Insights Cl√©s\n",
    "\n",
    "1.  **Corr√©lation Urgence :** La plupart des tickets \"security\" sont **High Urgency** ‚Üí logique pour des incidents sensibles (fuite de donn√©es, acc√®s pirat√©).\n",
    "2.  **Cat√©gories d'origine :** Souvent cach√©s dans *Technical Support* ou *IT Support*.\n",
    "3.  **Th√®mes r√©currents :** `unauthorized access`, `data breach`, `outdated security`, `password reset`, `healthcare context`.\n",
    "\n",
    "### üöÄ Suggestions pour la suite du projet\n",
    "\n",
    "* **Am√©liorer le raffinement des classes :**\n",
    "    * Ajoute plus de **keywords** pour la classe *Security* (ex. `breach`, `unauthorized`, `hack`, `malware`, `encrypt`, `hipaa`).\n",
    "    * Ajoute plus de keywords pour *Network* (`vpn`, `wifi`, `router`, `connectivity`).\n",
    "    * *Action :* Relance le DAG de pr√©paration si besoin pour affiner la colonne `refined_queue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66f60b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne refined_queue cr√©√©e et mise √† jour !\n",
      "\n",
      "=== Distribution des refined_queue ===\n",
      "Software / Product             :  6604 (36.9%)\n",
      "General Technical Support      :  4679 (26.1%)\n",
      "Security / Access              :  4165 (23.3%)\n",
      "Network / Infrastructure       :  1196 (6.7%)\n",
      "Hardware / Device              :   745 (4.2%)\n",
      "Service Outages                :   466 (2.6%)\n",
      "Printer / Peripherals          :    38 (0.2%)\n"
     ]
    }
   ],
   "source": [
    "# on ajoute une colonne refined_queue pour cr√©er une classification plus fine en 7 cat√©gories\n",
    "                                                                                            \n",
    "conn = psycopg2.connect(                                                                    \n",
    "    host=\"localhost\", port=5433,\n",
    "    database=\"support_tech\",\n",
    "    user=\"bootcamp_user\", password=\"bootcamp_password\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Ajoute la colonne refined_queue\n",
    "cur.execute(\"\"\"\n",
    "    ALTER TABLE tickets_tech_en_enriched \n",
    "    ADD COLUMN IF NOT EXISTS refined_queue VARCHAR(100);\n",
    "\"\"\")\n",
    "\n",
    "# Met √† jour avec la logique de classification\n",
    "cur.execute(\"\"\"\n",
    "    UPDATE tickets_tech_en_enriched\n",
    "    SET refined_queue = CASE\n",
    "        WHEN has_security = 1 THEN 'Security / Access'\n",
    "        WHEN has_printer = 1 THEN 'Printer / Peripherals'\n",
    "        WHEN has_hardware = 1 THEN 'Hardware / Device'\n",
    "        WHEN has_network = 1 THEN 'Network / Infrastructure'\n",
    "        WHEN has_software = 1 OR queue = 'Product Support' THEN 'Software / Product'\n",
    "        WHEN queue = 'Service Outages and Maintenance' THEN 'Service Outages'\n",
    "        ELSE 'General Technical Support'\n",
    "    END;\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "print(\"Colonne refined_queue cr√©√©e et mise √† jour !\")\n",
    "\n",
    "# V√©rifie la distribution\n",
    "cur.execute(\"\"\"\n",
    "    SELECT refined_queue, COUNT(*) as count,  \n",
    "            ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 1) as pct\n",
    "    FROM tickets_tech_en_enriched\n",
    "    GROUP BY refined_queue\n",
    "    ORDER BY count DESC;\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n=== Distribution des refined_queue ===\")\n",
    "for row in cur.fetchall():\n",
    "    print(f\"{row[0]:<30} : {row[1]:>5} ({row[2]}%)\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbae2df8",
   "metadata": {},
   "source": [
    "## üìä Analyse de la distribution : `refined_queue`\n",
    "\n",
    "Parfait ! La colonne `refined_queue` est cr√©√©e et mise √† jour. On a maintenant une granularit√© beaucoup plus fine et r√©aliste pour ton agent support technique interne.\n",
    "\n",
    "### 1. Distribution finale des classes (sur 17 893 tickets)\n",
    "\n",
    "| Classe `refined_queue` | Tickets | % | Commentaire / Utilisation projet |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Software / Product** | 6 604 | **36.9 %** | Dominant ‚Üí bugs, apps, mises √† jour, features |\n",
    "| **General Technical Support** | 4 679 | **26.1 %** | \"Catch-all\" technique g√©n√©ral |\n",
    "| **Security / Access** | 4 165 | **23.3 %** | **Tr√®s √©lev√© !** ‚Üí acc√®s, login, breach, password |\n",
    "| **Network / Infrastructure** | 1 196 | **6.7 %** | VPN, connexion, wifi, router, infra |\n",
    "| **Hardware / Device** | 745 | **4.2 %** | PC, MacBook, √©cran, disque, p√©riph√©riques |\n",
    "| **Service Outages** | 466 | **2.6 %** | Pannes, maintenance planifi√©e |\n",
    "| **Printer / Peripherals** | 38 | **0.2 %** | Tr√®s rare ‚Üí imprimantes, scan |\n",
    "\n",
    "### 2. Observations Cl√©s üßê\n",
    "* **Concentration :** 3 classes couvrent d√©j√† **~86 %** des tickets (Software + General + Security) ‚Üí tr√®s bon √©quilibre pour un mod√®le de classification.\n",
    "* **S√©curit√© :** La classe *Security* est beaucoup plus pr√©sente (23.3 %) que ce que les queues brutes laissaient penser (0.8‚Äì5 %). Gr√¢ce aux keywords, on capture bien les incidents sensibles (*breach, unauthorized, outdated security*).\n",
    "* **Optimisation :** *Printer* reste marginal. Tu peux le fusionner dans *Hardware / Device* pour r√©duire √† 6 classes.\n",
    "* **Conclusion :** 7 classes (ou 6 si merge) ‚Üí pile dans la cible 6‚Äì12, et beaucoup plus repr√©sentatif d'un vrai helpdesk IT (software dominant, s√©curit√© critique, hardware/r√©seau secondaires).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Implications pour le projet Bootcamp üöÄ\n",
    "\n",
    "#### A. Classification ML (Prochain DAG)\n",
    "* **Target principal :** `refined_queue` (7 classes).\n",
    "* **Target secondaire :** `urgency_level` (3 classes).\n",
    "* **Features :**\n",
    "    * *Text :* TF-IDF ou MiniLM embeddings sur `body_clean` + `subject`.\n",
    "    * *Num√©riques :* `body_length`, `answer_length`, `response_ratio`, `has_*` (d√©j√† calcul√©s).\n",
    "* **Mod√®le :** XGBoost (multi-class).\n",
    "* **Avantage :** Les keywords (`has_*`) deviennent des features puissantes ‚Üí boost de performance.\n",
    "\n",
    "#### B. RAG (Retrieval Augmented Generation)\n",
    "* Les docs RAG peuvent inclure `refined_queue` dans les **metadata** pour filtrer.\n",
    "* *Exemple :* \"R√©cup√®re les tickets similaires dans la cat√©gorie *Security / Access* seulement\".\n",
    "\n",
    "#### C. Monitoring (Evidently)\n",
    "* Tu peux maintenant monitorer le **Drift** sur `refined_queue` (distribution des th√®mes) en plus des longueurs et keywords.\n",
    "* *Exemple :* Si *Security / Access* augmente fortement ‚Üí alerte \"augmentation des incidents s√©curit√©\".\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Actions Imm√©diates (SQL) üõ†Ô∏è\n",
    "\n",
    "**V√©rifier la distribution :**\n",
    "```sql\n",
    "SELECT refined_queue,\n",
    "       COUNT(*) AS count,\n",
    "       ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) AS pct\n",
    "FROM tickets_tech_en_enriched\n",
    "GROUP BY refined_queue\n",
    "ORDER BY count DESC;\n",
    "```\n",
    "**(Optionnel) Fusionner Printer dans Hardware :**\n",
    "```sql\n",
    "UPDATE tickets_tech_en_enriched\n",
    "SET refined_queue = 'Hardware / Device'\n",
    "WHERE refined_queue = 'Printer / Peripherals';\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc1b3f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusionn√© : 38 tickets Printer ‚Üí Hardware\n",
      "\n",
      "=== Distribution finale (6 classes) ===\n",
      "Software / Product             :  6604 (36.9%)\n",
      "General Technical Support      :  4679 (26.1%)\n",
      "Security / Access              :  4165 (23.3%)\n",
      "Network / Infrastructure       :  1196 (6.7%)\n",
      "Hardware / Device              :   783 (4.4%)\n",
      "Service Outages                :   466 (2.6%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\", port=5433,\n",
    "    database=\"support_tech\",\n",
    "    user=\"bootcamp_user\", password=\"bootcamp_password\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Fusionne Printer dans Hardware\n",
    "cur.execute(\"\"\"\n",
    "    UPDATE tickets_tech_en_enriched\n",
    "    SET refined_queue = 'Hardware / Device'\n",
    "    WHERE refined_queue = 'Printer / Peripherals';\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(f\"Fusionn√© : {cur.rowcount} tickets Printer ‚Üí Hardware\")\n",
    "\n",
    "# Nouvelle distribution\n",
    "cur.execute(\"\"\"\n",
    "    SELECT refined_queue, COUNT(*) as count, \n",
    "            ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 1) as pct\n",
    "    FROM tickets_tech_en_enriched\n",
    "    GROUP BY refined_queue\n",
    "    ORDER BY count DESC;\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n=== Distribution finale (6 classes) ===\")\n",
    "for row in cur.fetchall():\n",
    "    print(f\"{row[0]:<30} : {row[1]:>5} ({row[2]}%)\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fb7c5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Distribution refined_queue ===\n",
      "Software / Product             :  6604 (36.9%)\n",
      "General Technical Support      :  4679 (26.1%)\n",
      "Security / Access              :  4165 (23.3%)\n",
      "Network / Infrastructure       :  1196 (6.7%)\n",
      "Hardware / Device              :   783 (4.4%)\n",
      "Service Outages                :   466 (2.6%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\", port=5433,\n",
    "    database=\"support_tech\",\n",
    "    user=\"bootcamp_user\", password=\"bootcamp_password\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT refined_queue,\n",
    "            COUNT(*) AS count,\n",
    "            ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) AS pct\n",
    "    FROM tickets_tech_en_enriched\n",
    "    GROUP BY refined_queue\n",
    "    ORDER BY count DESC;\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== Distribution refined_queue ===\")\n",
    "for row in cur.fetchall():\n",
    "    print(f\"{row[0]:<30} : {row[1]:>5} ({row[2]}%)\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9ace877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Exemples tickets Network / Infrastructure ===\n",
      "\n",
      "[high] None\n",
      "   Facing connectivity problems with Google Nest Wifi Router...\n",
      "\n",
      "[high] Service Disruption\n",
      "   Encountering several device-related service interruptions impacting workflow. Attempts to resolve by rebooting devices and checking internet connectiv...\n",
      "\n",
      "[low] Problem with investment data failing to update properly\n",
      "   Description: Investment data is not updating as expected. Possible causes: API connection problems or out-of-date software. Efforts made: Restarted eq...\n",
      "\n",
      "[high] Project Sync Failure\n",
      "   Below is a brief issue description: The project sync has failed. It might be related to a MongoDB connection problem. Steps taken: Restarted Docker, v...\n",
      "\n",
      "[medium] None\n",
      "   We are encountering connectivity problems with the SaaS project management tool on my iMac, which might be related to network instability with the Goo...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\", port=5433,\n",
    "    database=\"support_tech\",\n",
    "    user=\"bootcamp_user\", password=\"bootcamp_password\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT subject, LEFT(body_clean, 150) as preview, urgency_level\n",
    "    FROM tickets_tech_en_enriched\n",
    "    WHERE refined_queue = 'Network / Infrastructure'\n",
    "    LIMIT 5;\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== Exemples tickets Network / Infrastructure ===\\n\")\n",
    "for row in cur.fetchall():\n",
    "    print(f\"[{row[2]}] {row[0]}\")\n",
    "    print(f\"   {row[1]}...\\n\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ed842",
   "metadata": {},
   "source": [
    "### üåê Analyse : Focus sur \"Network / Infrastructure\"\n",
    "\n",
    "On voit que ce sont tous des probl√®mes de connexion/r√©seau :\n",
    "\n",
    "| Ticket | Probl√®me |\n",
    "| :--- | :--- |\n",
    "| **Google Nest Wifi Router** | Connectivity problems |\n",
    "| **Service Disruption** | Internet connectivity issues |\n",
    "| **Investment data** | API connection problems |\n",
    "| **Project Sync Failure** | MongoDB connection problem |\n",
    "| **SaaS tool** | Network instability |\n",
    "\n",
    "üîç **Mots-cl√©s d√©tect√©s :** `connectivity`, `connection`, `network`, `wifi`, `router`\n",
    "\n",
    "---\n",
    "\n",
    "### üìã R√©capitulatif final des 6 classes\n",
    "\n",
    "Voici la structure finale de ta colonne cible `refined_queue` :\n",
    "\n",
    "| Classe `refined_queue` | C'est quoi ? (Description) |\n",
    "| :--- | :--- |\n",
    "| **Software / Product** | Bugs, apps, updates, installations |\n",
    "| **General Technical Support** | Probl√®mes techniques g√©n√©raux (Catch-all) |\n",
    "| **Security / Access** | Login, passwords, data breach, acc√®s |\n",
    "| **Network / Infrastructure** | VPN, wifi, connexion, r√©seau |\n",
    "| **Hardware / Device** | PC, laptop, √©cran, imprimante |\n",
    "| **Service Outages** | Pannes, maintenance planifi√©e |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
